{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8da7bd5-e38b-42aa-af52-46e2560f6f48",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-20 20:37:39.393994: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-20 20:37:40.620128: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "\n",
    "import torchvision\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.io import read_image\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0de11d51-2916-469d-83b2-acf46c5f89e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.set_device(1)\n",
    "device = torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cae0dfbb-718e-43e9-a0c5-f534eff2dedf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0]+'.jpg')\n",
    "        #print(os.path.isdir(self.img_dir))\n",
    "        #print(os.listdir(self.img_dir))\n",
    "        image = read_image(img_path)/255.\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa4a90a3-6353-4714-9641-ff0dd1818635",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "idrid_train = CustomImageDataset(csv_file='IDRiD/train.csv',\n",
    "                             img_dir='IDRiD/B. Disease Grading/1. Original Images/a. Training Set',\n",
    "                             transform=transforms.Compose([transforms.ToPILImage(),\n",
    "                                                           transforms.RandomHorizontalFlip(p=0.5),\n",
    "                                                           transforms.RandomVerticalFlip(p=0.3),\n",
    "                                                           transforms.ColorJitter(brightness=0.1,\n",
    "                                                                                  contrast=0.1,\n",
    "                                                                                  saturation=0.01,\n",
    "                                                                                  hue=0.01),\n",
    "                                                           transforms.ToTensor(),\n",
    "                                                           \n",
    "                                                           transforms.Resize((512,512)),\n",
    "                                                           \n",
    "                                                          ])\n",
    "                            )\n",
    "idrid_val = CustomImageDataset(csv_file='IDRiD/val.csv',\n",
    "                             img_dir='IDRiD/B. Disease Grading/1. Original Images/a. Training Set',\n",
    "                             transform=transforms.Compose([transforms.ToPILImage(),\n",
    "                                                           transforms.ToTensor(),\n",
    "                                                           \n",
    "                                                           transforms.Resize((512,512))\n",
    "                                                          ])\n",
    "                            )\n",
    "idrid_test = CustomImageDataset(csv_file='IDRiD/B. Disease Grading/2. Groundtruths/b. IDRiD_Disease Grading_Testing Labels.csv',\n",
    "                             img_dir='IDRiD/B. Disease Grading/1. Original Images/b. Testing Set',\n",
    "                             transform=transforms.Compose([transforms.ToPILImage(),\n",
    "                                                           transforms.ToTensor(),\n",
    "                                                           \n",
    "                                                           transforms.Resize((512,512))\n",
    "                                                          ])\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfb6904b-ecfd-41b5-ba8d-2181c7231691",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "train_dataloader = DataLoader(idrid_train, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(idrid_val, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(idrid_test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31979a3-c879-42c1-b928-e90c46d13b41",
   "metadata": {},
   "source": [
    "# MODEL DEFINITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b62371c9-56fa-4db2-a28f-bd5860ed1a06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nSamples = [107, 16, 109, 59, 39]\n",
    "norm_weights = [1 - (x / sum(nSamples)) for x in nSamples]\n",
    "model_weights = torch.tensor(norm_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cc170f6-142c-44a3-9deb-6b7e6237dc40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mainuser/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/mainuser/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "\n",
    "class TransferInceptionV3(nn.Module):\n",
    "    def __init__(self, num_classes=5, dropout=0.5):\n",
    "        super(TransferInceptionV3, self).__init__()\n",
    "        self.features = models.inception_v3(pretrained=True)\n",
    "        self.features.aux_logits = False \n",
    "        for param in self.features.parameters():\n",
    "            param.requires_grad = True\n",
    "        self.fc1 = nn.Linear(1000, 256)\n",
    "        self.fc2 = nn.Linear(256,64)\n",
    "        self.fc3 = nn.Linear(64, num_classes)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.leaky_relu = nn.LeakyReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        #x = x.logits\n",
    "        #x = x.view(x.size(0), -1)\n",
    "        #print(x.shape)\n",
    "        x = self.dropout(self.leaky_relu(self.fc1(x)))\n",
    "        x = self.dropout(self.leaky_relu(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = TransferInceptionV3()\n",
    "model.load_state_dict(torch.load('idrid_best_scratch_weighted.pt'))\n",
    "model = model.to(torch.cuda.current_device())\n",
    "#Weighted\n",
    "criterion = nn.CrossEntropyLoss(weight=model_weights.to(torch.cuda.current_device()))\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# optimizer = optim.RMSprop(model.parameters(), lr=0.001)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1164992-9748-4682-bb3d-4aad92b79024",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mainuser/.local/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0189, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6434, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6980, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6933, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7007, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7229, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1749, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6942, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8503, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0381, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7203, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "VALIDATING\n",
      "tensor(0.7151, device='cuda:1')\n",
      "tensor(24, device='cuda:1')\n",
      "tensor(0.8127, device='cuda:1')\n",
      "tensor(22, device='cuda:1')\n",
      "tensor(0.9355, device='cuda:1')\n",
      "tensor(11, device='cuda:1')\n",
      "Epoch 1/10: Train Loss = 0.8204, Val Loss = 0.8032\n",
      "Updating best model...\n",
      "Epoch took 8.0 minutes\n",
      "tensor(0.7900, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7461, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9654, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7792, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7824, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0568, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5825, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8758, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5902, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6512, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9770, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "VALIDATING\n",
      "tensor(0.8998, device='cuda:1')\n",
      "tensor(19, device='cuda:1')\n",
      "tensor(0.8796, device='cuda:1')\n",
      "tensor(23, device='cuda:1')\n",
      "tensor(0.5059, device='cuda:1')\n",
      "tensor(15, device='cuda:1')\n",
      "Epoch 2/10: Train Loss = 0.7879, Val Loss = 0.8018\n",
      "Updating best model...\n",
      "Epoch took 8.0 minutes\n",
      "tensor(0.8948, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5975, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5903, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5484, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6908, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7730, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8206, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8956, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8230, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9837, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4522, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "VALIDATING\n",
      "tensor(0.8462, device='cuda:1')\n",
      "tensor(19, device='cuda:1')\n",
      "tensor(0.7107, device='cuda:1')\n",
      "tensor(24, device='cuda:1')\n",
      "tensor(0.9388, device='cuda:1')\n",
      "tensor(12, device='cuda:1')\n",
      "Epoch 3/10: Train Loss = 0.7524, Val Loss = 0.8152\n",
      "Epoch took 8.0 minutes\n",
      "tensor(0.9028, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5916, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8931, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8379, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7977, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5621, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6892, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7413, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7008, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8200, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6045, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "VALIDATING\n",
      "tensor(0.9610, device='cuda:1')\n",
      "tensor(18, device='cuda:1')\n",
      "tensor(0.8105, device='cuda:1')\n",
      "tensor(21, device='cuda:1')\n",
      "tensor(0.5605, device='cuda:1')\n",
      "tensor(16, device='cuda:1')\n",
      "Epoch 4/10: Train Loss = 0.7491, Val Loss = 0.8113\n",
      "Epoch took 8.0 minutes\n",
      "tensor(0.6842, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9045, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5777, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1213, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6172, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7572, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8768, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6946, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6671, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5929, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7096, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "VALIDATING\n",
      "tensor(0.7544, device='cuda:1')\n",
      "tensor(18, device='cuda:1')\n",
      "tensor(0.9239, device='cuda:1')\n",
      "tensor(20, device='cuda:1')\n",
      "tensor(0.7619, device='cuda:1')\n",
      "tensor(13, device='cuda:1')\n",
      "Epoch 5/10: Train Loss = 0.7481, Val Loss = 0.8214\n",
      "Epoch took 8.0 minutes\n",
      "tensor(0.7062, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9711, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7028, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5675, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7526, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8837, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7897, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5227, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4851, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7385, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6753, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "VALIDATING\n",
      "tensor(0.8516, device='cuda:1')\n",
      "tensor(20, device='cuda:1')\n",
      "tensor(0.8332, device='cuda:1')\n",
      "tensor(21, device='cuda:1')\n",
      "tensor(0.7243, device='cuda:1')\n",
      "tensor(12, device='cuda:1')\n",
      "Epoch 6/10: Train Loss = 0.7109, Val Loss = 0.8154\n",
      "Epoch took 8.0 minutes\n",
      "tensor(0.5324, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6408, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6299, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9036, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8461, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6418, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7170, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6068, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7131, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7699, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6086, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "VALIDATING\n",
      "tensor(1.0052, device='cuda:1')\n",
      "tensor(18, device='cuda:1')\n",
      "tensor(0.7664, device='cuda:1')\n",
      "tensor(21, device='cuda:1')\n",
      "tensor(0.5421, device='cuda:1')\n",
      "tensor(16, device='cuda:1')\n",
      "Epoch 7/10: Train Loss = 0.6974, Val Loss = 0.8072\n",
      "Epoch took 8.0 minutes\n",
      "tensor(1.3352, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6299, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6319, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6648, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7589, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7706, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7996, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7635, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5457, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6677, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0000, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "VALIDATING\n",
      "tensor(0.7837, device='cuda:1')\n",
      "tensor(19, device='cuda:1')\n",
      "tensor(0.9069, device='cuda:1')\n",
      "tensor(20, device='cuda:1')\n",
      "tensor(0.7257, device='cuda:1')\n",
      "tensor(13, device='cuda:1')\n",
      "Epoch 8/10: Train Loss = 0.7642, Val Loss = 0.8179\n",
      "Epoch took 8.0 minutes\n",
      "tensor(0.7605, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7882, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7981, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5816, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1572, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6993, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4952, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7866, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7394, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7657, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6397, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "VALIDATING\n",
      "tensor(0.8430, device='cuda:1')\n",
      "tensor(21, device='cuda:1')\n",
      "tensor(0.8964, device='cuda:1')\n",
      "tensor(21, device='cuda:1')\n",
      "tensor(0.6880, device='cuda:1')\n",
      "tensor(14, device='cuda:1')\n",
      "Epoch 9/10: Train Loss = 0.7536, Val Loss = 0.8281\n",
      "Epoch took 8.0 minutes\n",
      "tensor(0.9776, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7867, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7027, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5603, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8005, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9327, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7328, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5221, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6918, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6569, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0999, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "VALIDATING\n",
      "tensor(0.9911, device='cuda:1')\n",
      "tensor(20, device='cuda:1')\n",
      "tensor(0.7460, device='cuda:1')\n",
      "tensor(22, device='cuda:1')\n",
      "tensor(0.7061, device='cuda:1')\n",
      "tensor(13, device='cuda:1')\n",
      "Epoch 10/10: Train Loss = 0.7777, Val Loss = 0.8313\n",
      "Epoch took 8.0 minutes\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "All_train_loss = []\n",
    "All_val_loss = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = timeit.default_timer()\n",
    "    \n",
    "    # Train the model on the training set\n",
    "    total_train_loss = 0\n",
    "    model.train()\n",
    "    for images, labels in train_dataloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        #take argmax of the logits before computing the loss?\n",
    "        outputs = model(images)\n",
    "        #logits = outputs.logits\n",
    "        loss = criterion(outputs, labels)\n",
    "        total_train_loss += loss * images.shape[0]\n",
    "        print(loss)\n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Evaluate the model on the validation set\n",
    "    print(\"VALIDATING\")\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in val_dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            #logits = outputs.logits\n",
    "            #take argmax of the logits before computing the loss \n",
    "            #outputs = outputs.softmax(dim=1)\n",
    "            val_loss = criterion(outputs, labels)\n",
    "            print(val_loss)\n",
    "            total_val_loss += val_loss.item() * images.shape[0]\n",
    "            #take argmax of the logits before computing the loss \n",
    "            predicted = torch.argmax(outputs, 1) #did torch.argmax instead of torch.max\n",
    "            total += labels.size(0)\n",
    "            print((predicted == labels).sum())\n",
    "            correct += (predicted == labels).sum()\n",
    "    avg_train_loss = total_train_loss/330\n",
    "    avg_val_loss = total_val_loss/83\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}: Train Loss = {avg_train_loss:.4f}, Val Loss = {avg_val_loss:.4f}\")\n",
    "    All_train_loss.append(avg_train_loss.cpu())\n",
    "    All_val_loss.append(avg_val_loss)\n",
    "    \n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        print(\"Updating best model...\")\n",
    "        torch.save(model.state_dict(), 'idrid_best_sgd.pt')\n",
    "    \n",
    "    elapsed = timeit.default_timer() - start_time\n",
    "    print(\"Epoch took\", str(elapsed//60), \"minutes\")\n",
    "        \n",
    "\n",
    "torch.save(model.state_dict(), 'idrid_last_sgd.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "600e4fc6-4349-4657-b57c-3b0dc2cdcb1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(All_val_loss)\n",
    "All_val_loss = list(All_val_loss)\n",
    "All_train_loss = list(All_train_loss)\n",
    "with open(\"sgd_idrid_train_loss.txt\", 'w') as f:\n",
    "    for val in All_train_loss:\n",
    "        v = val.detach().numpy()\n",
    "        f.write(str(v))\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "with open(\"sgd_idrid_val_loss.txt\", 'w') as f:\n",
    "    for val in All_val_loss:\n",
    "        \n",
    "        v = val\n",
    "        f.write(str(v))\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45f4cb49-168f-4d34-a57e-fab51f319b78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mainuser/.local/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.5437\n",
      "Test F1 Score: 0.5212\n",
      "kappa score: 0.377283\n"
     ]
    }
   ],
   "source": [
    "### Testing             \n",
    "from sklearn.metrics import accuracy_score, f1_score, cohen_kappa_score\n",
    "\n",
    "#model = TransferInceptionV3()\n",
    "#model.load_state_dict(torch.load('idrid_best_adam.pt'))\n",
    "#model = model.to(torch.cuda.current_device())\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for images, labels in test_dataloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        predicted = torch.argmax(outputs, 1)\n",
    "        y_true.extend(labels.cpu())\n",
    "        y_pred.extend(predicted.cpu())\n",
    "\n",
    "# Compute the accuracy and F1 score\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "kappa = cohen_kappa_score(y_true, y_pred)\n",
    "\n",
    "print(f'Test Accuracy: {accuracy:.4f}')\n",
    "print(f'Test F1 Score: {f1:.4f}')\n",
    "\n",
    "print(f'kappa score: {kappa:4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d4aa590-0829-4488-8aaf-ff9c400b029e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28  0  6  0  0]\n",
      " [ 3  0  2  0  0]\n",
      " [ 6  0 13 11  2]\n",
      " [ 2  0  2 11  4]\n",
      " [ 1  0  3  5  4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.700     0.824     0.757        34\n",
      "           1      0.000     0.000     0.000         5\n",
      "           2      0.500     0.406     0.448        32\n",
      "           3      0.407     0.579     0.478        19\n",
      "           4      0.400     0.308     0.348        13\n",
      "\n",
      "    accuracy                          0.544       103\n",
      "   macro avg      0.401     0.423     0.406       103\n",
      "weighted avg      0.512     0.544     0.521       103\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mainuser/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mainuser/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mainuser/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "# Print the confusion matrix\n",
    "print(metrics.confusion_matrix(y_true, y_pred))\n",
    "\n",
    "# Print the precision and recall, among other metrics\n",
    "print(metrics.classification_report(y_true, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbeeeff-57fd-4589-9d0b-7d0010cbaa85",
   "metadata": {},
   "source": [
    "# PLOTTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f872ca1-6c71-4189-87d8-6717e92177ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss_plot = []\n",
    "for value in All_train_loss:\n",
    "    v = value.detach().numpy()\n",
    "    train_loss_plot.append(v)\n",
    "plt.plot(train_loss_plot, label='Training Loss')\n",
    "plt.plot(All_val_loss,label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show\n",
    "plt.savefig('idrid_sgd_trainLossValLoss.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a7e522-9601-4c59-8348-444847e338b3",
   "metadata": {},
   "source": [
    "## Predictability Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b3e05ad-1c55-44b5-bf1c-ddb50626af82",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_paths = {\n",
    "    'Backbone': 'IDRID Backbone/idrid_last_backbone.pt',\n",
    "    'Unweighted Scratch': 'IDRID Scratch/idrid_last_scratch.pt',\n",
    "    'Weighted Scratch': 'IDRID Weighted Correct/idrid_best_scratch_weighted.pt',\n",
    "    'CLAHE': 'IDRID CLAHE /idrid_last_clahe.pt'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e163def-7a3c-4026-a5b3-53a66616e645",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------| Backbone |----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mainuser/.local/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.8152\n",
      "Train F1 Score: 0.8116\n",
      "Train Kappa score: 0.747460\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mainuser/.local/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 0.5542\n",
      "Val F1 Score: 0.5308\n",
      "Val Kappa score: 0.384075\n",
      "----------------| Unweighted Scratch |----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mainuser/.local/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.8394\n",
      "Train F1 Score: 0.8222\n",
      "Train Kappa score: 0.780348\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mainuser/.local/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 0.6265\n",
      "Val F1 Score: 0.6208\n",
      "Val Kappa score: 0.496182\n",
      "----------------| Weighted Scratch |----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mainuser/.local/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.6576\n",
      "Train F1 Score: 0.5945\n",
      "Train Kappa score: 0.508112\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mainuser/.local/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 0.6386\n",
      "Val F1 Score: 0.5755\n",
      "Val Kappa score: 0.484792\n",
      "----------------| CLAHE |----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mainuser/.local/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.7758\n",
      "Train F1 Score: 0.7542\n",
      "Train Kappa score: 0.691970\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mainuser/.local/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 0.6747\n",
      "Val F1 Score: 0.6548\n",
      "Val Kappa score: 0.553408\n"
     ]
    }
   ],
   "source": [
    "for _title in model_paths:\n",
    "    print(f\"----------------| {_title} |----------------\")\n",
    "    model.load_state_dict(torch.load(model_paths[_title]))\n",
    "    model = model.to(torch.cuda.current_device())\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        for images, labels in train_dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            predicted = torch.argmax(outputs, 1)\n",
    "            y_true.extend(labels.cpu())\n",
    "            y_pred.extend(predicted.cpu())\n",
    "\n",
    "    # Compute the accuracy and F1 score\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    kappa = cohen_kappa_score(y_true, y_pred)\n",
    "\n",
    "    print(f'Train Accuracy: {accuracy:.4f}')\n",
    "    print(f'Train F1 Score: {f1:.4f}')\n",
    "    print(f'Train Kappa score: {kappa:4f}')\n",
    "\n",
    "    print(f\"----------------\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        for images, labels in val_dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            predicted = torch.argmax(outputs, 1)\n",
    "            y_true.extend(labels.cpu())\n",
    "            y_pred.extend(predicted.cpu())\n",
    "\n",
    "    # Compute the accuracy and F1 score\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    kappa = cohen_kappa_score(y_true, y_pred)\n",
    "\n",
    "    print(f'Val Accuracy: {accuracy:.4f}')\n",
    "    print(f'Val F1 Score: {f1:.4f}')\n",
    "    print(f'Val Kappa score: {kappa:4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62956b3b-8829-4630-a550-9e0791704280",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
